{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten, ZeroPadding1D, Embedding\n",
    "\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "from tensorflow.python.keras.initializers import Constant\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Configuration variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_words = 15000\n",
    "epochs = 5\n",
    "embedding_dim = 300            # If you use pre trained embedding matrix, Make sure this variable is equal with it\n",
    "batch_size = 64\n",
    "num_class = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read dataset and getting ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>woody allen alem adam yine ortaya izlemesi key...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16306</th>\n",
       "      <td>kafaya koyduğunu yapabilmek i̇nsanoğlunun sahi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>harika farklı içinde kullanılan animasyonlar h...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>ben fılmı cıktıgı ılk zamanlarda ızlemıstım he...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35178</th>\n",
       "      <td>saçma filmdi kesinlikle zaman kaybı denzel bil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  point\n",
       "2918   woody allen alem adam yine ortaya izlemesi key...      2\n",
       "16306  kafaya koyduğunu yapabilmek i̇nsanoğlunun sahi...      2\n",
       "14998  harika farklı içinde kullanılan animasyonlar h...      2\n",
       "1988   ben fılmı cıktıgı ılk zamanlarda ızlemıstım he...      2\n",
       "35178  saçma filmdi kesinlikle zaman kaybı denzel bil...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/clean_dataset.csv')    # Read movie comments dataset             \n",
    "df = df.dropna()                         # Remove none type samples\n",
    "df = df.sample(frac=1) \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split dataset and make label categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oyuncular cekim cok cok amatördü hikayeyinin anlami yok yarim yamalak sacma bitis oldu begenemedim\n",
      "[1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "target = df['point'].values.tolist()                 # Get all points as a list\n",
    "data = df['comment'].values.tolist()                 # Get all comments as a list\n",
    "\n",
    "target = to_categorical(target, num_classes=num_class)                      # Convert label into one-hot vector\n",
    "\n",
    "cutoff = int(len(target) * 0.8)                      # Split dataset as train and test\n",
    "x_train, x_test = data[:cutoff], data[cutoff:]\n",
    "y_train, y_test = target[:cutoff], target[cutoff:]\n",
    "\n",
    "print(x_train[2340])\n",
    "print(y_train[2340])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iyi': 1,\n",
       " 'güzel': 2,\n",
       " 'olarak': 3,\n",
       " 'bence': 4,\n",
       " 'filmde': 5,\n",
       " 'var': 6,\n",
       " 'değil': 7,\n",
       " 'ben': 8,\n",
       " 'olan': 9,\n",
       " 'kötü': 10,\n",
       " 'yok': 11,\n",
       " 'sonra': 12,\n",
       " 'son': 13,\n",
       " 'gerçekten': 14,\n",
       " 'filme': 15,\n",
       " 'ilk': 16,\n",
       " 'bile': 17,\n",
       " 'biraz': 18,\n",
       " 'olmuş': 19,\n",
       " 'zaman': 20,\n",
       " 'başarılı': 21,\n",
       " 'kesinlikle': 22,\n",
       " 'fazla': 23,\n",
       " 'büyük': 24,\n",
       " 'zaten': 25,\n",
       " 'sadece': 26,\n",
       " 'tek': 27,\n",
       " 'tavsiye': 28,\n",
       " 'yine': 29,\n",
       " 'ancak': 30,\n",
       " 'harika': 31,\n",
       " 'özellikle': 32,\n",
       " 'böyle': 33,\n",
       " 'olduğunu': 34,\n",
       " 'olduğu': 35,\n",
       " 'tam': 36,\n",
       " 'fakat': 37,\n",
       " 'izledim': 38,\n",
       " 'senaryo': 39,\n",
       " 'konu': 40,\n",
       " 'farklı': 41,\n",
       " 'komedi': 42,\n",
       " 'cok': 43,\n",
       " 'aksiyon': 44,\n",
       " 'aynı': 45,\n",
       " 'pek': 46,\n",
       " 'oldukça': 47,\n",
       " 'bana': 48,\n",
       " 'şekilde': 49,\n",
       " 'filmdi': 50,\n",
       " 'sinema': 51,\n",
       " 'benim': 52,\n",
       " 'yer': 53,\n",
       " 'izleyin': 54,\n",
       " 'göre': 55,\n",
       " 'önce': 56,\n",
       " 'oyuncu': 57,\n",
       " 'korku': 58,\n",
       " 'yönetmen': 59,\n",
       " 'iki': 60,\n",
       " 'rağmen': 61,\n",
       " 'ayrıca': 62,\n",
       " 'mükemmel': 63,\n",
       " 'filmleri': 64,\n",
       " 'ederim': 65,\n",
       " 'olsa': 66,\n",
       " 'konusu': 67,\n",
       " 'filmden': 68,\n",
       " 'eğlenceli': 69,\n",
       " 'olması': 70,\n",
       " 'uzun': 71,\n",
       " 'türk': 72,\n",
       " 'gereken': 73,\n",
       " 'izlediğim': 74,\n",
       " 'nin': 75,\n",
       " 'beni': 76,\n",
       " 'filmlerden': 77,\n",
       " 'bunu': 78,\n",
       " 'gayet': 79,\n",
       " 'the': 80,\n",
       " 'yapım': 81,\n",
       " 'diğer': 82,\n",
       " 'izlerken': 83,\n",
       " 'gerçek': 84,\n",
       " 'başka': 85,\n",
       " 'oyunculuk': 86,\n",
       " 'içinde': 87,\n",
       " 'kendi': 88,\n",
       " 'filmler': 89,\n",
       " 'oldu': 90,\n",
       " 'olur': 91,\n",
       " 'gerilim': 92,\n",
       " 'komik': 93,\n",
       " 'süper': 94,\n",
       " 'hatta': 95,\n",
       " 'gerek': 96,\n",
       " 'mutlaka': 97,\n",
       " 'adam': 98,\n",
       " 'öyle': 99,\n",
       " 'yeni': 100,\n",
       " 'onun': 101,\n",
       " 'artık': 102,\n",
       " 'sahneleri': 103,\n",
       " 'muhteşem': 104,\n",
       " 'ortaya': 105,\n",
       " 'filmlerinden': 106,\n",
       " 'insan': 107,\n",
       " 'sıkıcı': 108,\n",
       " 'olsun': 109,\n",
       " 'etkileyici': 110,\n",
       " 'devam': 111,\n",
       " 'bunun': 112,\n",
       " 'sahneler': 113,\n",
       " 'hoş': 114,\n",
       " 'saçma': 115,\n",
       " 'puan': 116,\n",
       " 'güzeldi': 117,\n",
       " 'hayal': 118,\n",
       " 'dışında': 119,\n",
       " 'oyuncular': 120,\n",
       " 'izlemek': 121,\n",
       " 'beğendim': 122,\n",
       " 'kendini': 123,\n",
       " 'sonunda': 124,\n",
       " 'sonu': 125,\n",
       " 'filmdeki': 126,\n",
       " 'düşünüyorum': 127,\n",
       " 'oyunculuklar': 128,\n",
       " 'önemli': 129,\n",
       " 'sahne': 130,\n",
       " 'bütün': 131,\n",
       " 'sahnesi': 132,\n",
       " 'sahip': 133,\n",
       " 'doğru': 134,\n",
       " 'basit': 135,\n",
       " 'hiçbir': 136,\n",
       " 'kurgu': 137,\n",
       " 'vardı': 138,\n",
       " 'tekrar': 139,\n",
       " 'klasik': 140,\n",
       " 'onu': 141,\n",
       " 'aşk': 142,\n",
       " 'sinemada': 143,\n",
       " 'olmayan': 144,\n",
       " 'hikaye': 145,\n",
       " 'vakit': 146,\n",
       " 'berbat': 147,\n",
       " 'değer': 148,\n",
       " 'müthiş': 149,\n",
       " 'merak': 150,\n",
       " 'arasında': 151,\n",
       " 'üzerine': 152,\n",
       " 'geçen': 153,\n",
       " 'seyirler': 154,\n",
       " 'kaliteli': 155,\n",
       " 'ediyor': 156,\n",
       " 'yazık': 157,\n",
       " 'ediyorum': 158,\n",
       " 'belli': 159,\n",
       " 'derim': 160,\n",
       " 'diyebilirim': 161,\n",
       " 'nın': 162,\n",
       " 'i̇yi': 163,\n",
       " 'zor': 164,\n",
       " 'arada': 165,\n",
       " 'tabi': 166,\n",
       " 'eden': 167,\n",
       " 'boş': 168,\n",
       " 'şeyler': 169,\n",
       " 'dolu': 170,\n",
       " 'sıradan': 171,\n",
       " 'arkadaşlar': 172,\n",
       " 'gereksiz': 173,\n",
       " 'geldi': 174,\n",
       " 'genel': 175,\n",
       " 'sizi': 176,\n",
       " 'iyiydi': 177,\n",
       " 'olabilir': 178,\n",
       " 'oluyor': 179,\n",
       " 'yüzden': 180,\n",
       " 'vasat': 181,\n",
       " 'sonuna': 182,\n",
       " 'işte': 183,\n",
       " 'hala': 184,\n",
       " 'sanırım': 185,\n",
       " 'i̇lk': 186,\n",
       " 'romantik': 187,\n",
       " 'ilginç': 188,\n",
       " 'dram': 189,\n",
       " 'değildi': 190,\n",
       " 'yorum': 191,\n",
       " 'boyunca': 192,\n",
       " 'hakkında': 193,\n",
       " 'derece': 194,\n",
       " 'insanı': 195,\n",
       " 'ikinci': 196,\n",
       " 'küçük': 197,\n",
       " 'yönetmenin': 198,\n",
       " 'savaş': 199,\n",
       " 'amerikan': 200,\n",
       " 'kadın': 201,\n",
       " 'hemen': 202,\n",
       " 'tamamen': 203,\n",
       " 'karakter': 204,\n",
       " 'filmini': 205,\n",
       " 'olmasına': 206,\n",
       " 'izlenebilir': 207,\n",
       " 'ilgili': 208,\n",
       " 'görsel': 209,\n",
       " 'evet': 210,\n",
       " 'para': 211,\n",
       " 'fena': 212,\n",
       " 'çocuk': 213,\n",
       " 'animasyon': 214,\n",
       " 'insanın': 215,\n",
       " 'ayrı': 216,\n",
       " 'sürükleyici': 217,\n",
       " 'açıkçası': 218,\n",
       " 'yıl': 219,\n",
       " 'yerine': 220,\n",
       " 'oscar': 221,\n",
       " 'herkes': 222,\n",
       " 'varsa': 223,\n",
       " 'dan': 224,\n",
       " 'serinin': 225,\n",
       " 'izlenmesi': 226,\n",
       " 'kısa': 227,\n",
       " 'izlemeye': 228,\n",
       " 'hikayesi': 229,\n",
       " 'içine': 230,\n",
       " 'filminde': 231,\n",
       " 'birisi': 232,\n",
       " 'herkese': 233,\n",
       " 'senaryosu': 234,\n",
       " 'üzerinden': 235,\n",
       " 'olacak': 236,\n",
       " 'birlikte': 237,\n",
       " 'oyunculuğu': 238,\n",
       " 'ana': 239,\n",
       " 'tarz': 240,\n",
       " 'sonuç': 241,\n",
       " 'zamanda': 242,\n",
       " 'herkesin': 243,\n",
       " 'hele': 244,\n",
       " 'ağır': 245,\n",
       " 'keyifli': 246,\n",
       " 'buna': 247,\n",
       " 'dünya': 248,\n",
       " 'nun': 249,\n",
       " 'uzak': 250,\n",
       " 'filmlerini': 251,\n",
       " 'lazım': 252,\n",
       " 'yinede': 253,\n",
       " 'eski': 254,\n",
       " 'den': 255,\n",
       " 'size': 256,\n",
       " 'karşı': 257,\n",
       " 'kaybı': 258,\n",
       " 'görmek': 259,\n",
       " 'bize': 260,\n",
       " 'karakterler': 261,\n",
       " 'yapılmış': 262,\n",
       " 'tarafından': 263,\n",
       " 'falan': 264,\n",
       " 'hak': 265,\n",
       " 'karakteri': 266,\n",
       " 'şimdi': 267,\n",
       " 'geliyor': 268,\n",
       " 'olmak': 269,\n",
       " 'yüksek': 270,\n",
       " 'ona': 271,\n",
       " 'tabii': 272,\n",
       " 'bende': 273,\n",
       " 'filmle': 274,\n",
       " 'göz': 275,\n",
       " 'saat': 276,\n",
       " 'başyapıt': 277,\n",
       " 'keşke': 278,\n",
       " 'gelen': 279,\n",
       " 'birçok': 280,\n",
       " 'tahmin': 281,\n",
       " 'insanların': 282,\n",
       " 'olmasa': 283,\n",
       " 'çıkan': 284,\n",
       " 'resmen': 285,\n",
       " 'gün': 286,\n",
       " 'kişi': 287,\n",
       " 'kız': 288,\n",
       " 'buldum': 289,\n",
       " 'yada': 290,\n",
       " 'bol': 291,\n",
       " 'anlatan': 292,\n",
       " 'yaptığı': 293,\n",
       " 'yapılan': 294,\n",
       " 'bizim': 295,\n",
       " 'inanılmaz': 296,\n",
       " 'pişman': 297,\n",
       " 'hayatımda': 298,\n",
       " 'dikkat': 299,\n",
       " 'çekilmiş': 300,\n",
       " 'öncelikle': 301,\n",
       " 'sıkılmadan': 302,\n",
       " 'filmlerin': 303,\n",
       " 'yoksa': 304,\n",
       " 'insanlar': 305,\n",
       " 'kalmış': 306,\n",
       " 'aile': 307,\n",
       " 'oyuncuların': 308,\n",
       " 'sürekli': 309,\n",
       " 'çoğu': 310,\n",
       " 'klişe': 311,\n",
       " 'kere': 312,\n",
       " 'bundan': 313,\n",
       " 'yapımı': 314,\n",
       " 'kaç': 315,\n",
       " 'gerçekçi': 316,\n",
       " 'olay': 317,\n",
       " 'sağlam': 318,\n",
       " 'performansı': 319,\n",
       " 'duygusal': 320,\n",
       " 'yapan': 321,\n",
       " 'keyif': 322,\n",
       " 'tür': 323,\n",
       " 'sırf': 324,\n",
       " 'guzel': 325,\n",
       " 'burada': 326,\n",
       " 'altında': 327,\n",
       " 'baştan': 328,\n",
       " 'üzerinde': 329,\n",
       " 'kendine': 330,\n",
       " 'hayat': 331,\n",
       " 'sona': 332,\n",
       " 'vardır': 333,\n",
       " 'adamın': 334,\n",
       " 'alan': 335,\n",
       " 'değişik': 336,\n",
       " 'hollywood': 337,\n",
       " 'sinemaya': 338,\n",
       " 'açısından': 339,\n",
       " 'anlatıyor': 340,\n",
       " 'puanı': 341,\n",
       " 'azından': 342,\n",
       " 'genç': 343,\n",
       " 'kelimeyle': 344,\n",
       " 'yanında': 345,\n",
       " 'zayıf': 346,\n",
       " 'usta': 347,\n",
       " 'olmaz': 348,\n",
       " 'bır': 349,\n",
       " 'geri': 350,\n",
       " 'bişey': 351,\n",
       " 'süre': 352,\n",
       " 'anlamda': 353,\n",
       " 'adeta': 354,\n",
       " 'veriyor': 355,\n",
       " 'erkek': 356,\n",
       " 'ilgi': 357,\n",
       " 'olaylar': 358,\n",
       " 'tarzı': 359,\n",
       " 'yanı': 360,\n",
       " 'yere': 361,\n",
       " 'maalesef': 362,\n",
       " 'vizyona': 363,\n",
       " 'final': 364,\n",
       " 'filmlere': 365,\n",
       " 'yakın': 366,\n",
       " 'fazlasıyla': 367,\n",
       " 'zamanlarda': 368,\n",
       " 'oynamış': 369,\n",
       " 'bilim': 370,\n",
       " 'fılm': 371,\n",
       " 'yoktu': 372,\n",
       " 'veren': 373,\n",
       " 'başına': 374,\n",
       " 'anda': 375,\n",
       " 'dakika': 376,\n",
       " 'neredeyse': 377,\n",
       " 'tatmin': 378,\n",
       " 'demek': 379,\n",
       " 'gittim': 380,\n",
       " 'performans': 381,\n",
       " 'müzik': 382,\n",
       " 'umarım': 383,\n",
       " 'asla': 384,\n",
       " 'filmlerinin': 385,\n",
       " 'filminden': 386,\n",
       " 'doğrusu': 387,\n",
       " 'rol': 388,\n",
       " 'filmlerinde': 389,\n",
       " 'kalan': 390,\n",
       " 'adına': 391,\n",
       " 'yapmış': 392,\n",
       " 'filim': 393,\n",
       " 'hayran': 394,\n",
       " 'izlenmeli': 395,\n",
       " 'john': 396,\n",
       " 'müzikler': 397,\n",
       " 'başta': 398,\n",
       " 'açık': 399,\n",
       " 'hoşuma': 400,\n",
       " 'neyse': 401,\n",
       " 'olabilirdi': 402,\n",
       " 'kısacası': 403,\n",
       " 'beğenmedim': 404,\n",
       " 'müzikleri': 405,\n",
       " 'ara': 406,\n",
       " 'çizgi': 407,\n",
       " 'bi̇r': 408,\n",
       " 'yerde': 409,\n",
       " 'yanlış': 410,\n",
       " 'filmlerine': 411,\n",
       " 'bazen': 412,\n",
       " 'filmlerde': 413,\n",
       " 'izledikten': 414,\n",
       " 'ses': 415,\n",
       " 'aldığı': 416,\n",
       " 'sahnede': 417,\n",
       " 'türlü': 418,\n",
       " 'etmek': 419,\n",
       " 'fantastik': 420,\n",
       " 'görüntü': 421,\n",
       " 'izlenir': 422,\n",
       " 'çekici': 423,\n",
       " 'sanat': 424,\n",
       " 'yavaş': 425,\n",
       " 'kesin': 426,\n",
       " 'durum': 427,\n",
       " 'kamera': 428,\n",
       " 'ünlü': 429,\n",
       " 'oldum': 430,\n",
       " 'şeyi': 431,\n",
       " 'olmamış': 432,\n",
       " 'baya': 433,\n",
       " 'filminin': 434,\n",
       " 'karar': 435,\n",
       " 'çıkıyor': 436,\n",
       " 'eder': 437,\n",
       " 'düşük': 438,\n",
       " 'içerisinde': 439,\n",
       " 'yalnız': 440,\n",
       " 'hakkını': 441,\n",
       " 'bunlar': 442,\n",
       " 'gitti': 443,\n",
       " 'ele': 444,\n",
       " 'şunu': 445,\n",
       " 'efektler': 446,\n",
       " 'gidin': 447,\n",
       " 'çıkmış': 448,\n",
       " 'sonunu': 449,\n",
       " 'izlemenizi': 450,\n",
       " 'olurdu': 451,\n",
       " 'tom': 452,\n",
       " 'mümkün': 453,\n",
       " 'kırıklığı': 454,\n",
       " 'yapıyor': 455,\n",
       " 'aşırı': 456,\n",
       " 'güçlü': 457,\n",
       " 'gercekten': 458,\n",
       " 'kolay': 459,\n",
       " 'orta': 460,\n",
       " 'açıdan': 461,\n",
       " 'mesela': 462,\n",
       " 'zevk': 463,\n",
       " 'hitap': 464,\n",
       " 'yeniden': 465,\n",
       " 'eminim': 466,\n",
       " 'degil': 467,\n",
       " 'ufak': 468,\n",
       " 'kurgusu': 469,\n",
       " 'verdiği': 470,\n",
       " 'izlenebilecek': 471,\n",
       " 'söz': 472,\n",
       " 'kabul': 473,\n",
       " 'sakın': 474,\n",
       " 'üst': 475,\n",
       " 'istiyorum': 476,\n",
       " 'kendisini': 477,\n",
       " 'bizi': 478,\n",
       " 'yönetmeni': 479,\n",
       " 'kusursuz': 480,\n",
       " 'yapmak': 481,\n",
       " 'tamam': 482,\n",
       " 'başlıyor': 483,\n",
       " 'icin': 484,\n",
       " 'filmine': 485,\n",
       " 'işlenmiş': 486,\n",
       " 'amerika': 487,\n",
       " 'yerinde': 488,\n",
       " 'robert': 489,\n",
       " 'üzere': 490,\n",
       " 'dolayı': 491,\n",
       " 'geçirmek': 492,\n",
       " 'alıyor': 493,\n",
       " 'bekliyorum': 494,\n",
       " 'herşey': 495,\n",
       " 'baş': 496,\n",
       " 'kadrosu': 497,\n",
       " 'beraber': 498,\n",
       " 'tercih': 499,\n",
       " 'şiddetle': 500,\n",
       " 'baba': 501,\n",
       " 'söyleyebilirim': 502,\n",
       " 'gerekir': 503,\n",
       " 'özel': 504,\n",
       " 'dair': 505,\n",
       " 'hale': 506,\n",
       " 'önceki': 507,\n",
       " 'bilmiyorum': 508,\n",
       " 'işi': 509,\n",
       " 'ötesi': 510,\n",
       " 'geçiyor': 511,\n",
       " 'sevdiğim': 512,\n",
       " 'harikaydı': 513,\n",
       " 'lütfen': 514,\n",
       " 'karakterlerin': 515,\n",
       " 'izlemesi': 516,\n",
       " 'mutlu': 517,\n",
       " 'izlemiştim': 518,\n",
       " 'ciddi': 519,\n",
       " 'diyorum': 520,\n",
       " 'konusunda': 521,\n",
       " 'bakış': 522,\n",
       " 'başrol': 523,\n",
       " 'sapan': 524,\n",
       " 'beyaz': 525,\n",
       " 'sonuçta': 526,\n",
       " 'seri': 527,\n",
       " 'sinemasının': 528,\n",
       " 'konuyu': 529,\n",
       " 'kimse': 530,\n",
       " 'hayatta': 531,\n",
       " 'dediğim': 532,\n",
       " 'kendisi': 533,\n",
       " 'başında': 534,\n",
       " 'çalışan': 535,\n",
       " 'merakla': 536,\n",
       " 'tabiki': 537,\n",
       " 'sineması': 538,\n",
       " 'genelde': 539,\n",
       " 'izleme': 540,\n",
       " 'asıl': 541,\n",
       " 'hızlı': 542,\n",
       " 'herhalde': 543,\n",
       " 'normal': 544,\n",
       " 'doğal': 545,\n",
       " 'şöyle': 546,\n",
       " 'sahnelerde': 547,\n",
       " 'bugün': 548,\n",
       " 'almış': 549,\n",
       " 'mantık': 550,\n",
       " 'macera': 551,\n",
       " 'duygu': 552,\n",
       " 'gidip': 553,\n",
       " 'yıllarda': 554,\n",
       " 'izlenmeye': 555,\n",
       " 'mesaj': 556,\n",
       " 'gitmeyin': 557,\n",
       " 'izlemedim': 558,\n",
       " 'kaçırmayın': 559,\n",
       " 'alıp': 560,\n",
       " 'oynadığı': 561,\n",
       " 'dvd': 562,\n",
       " 'kara': 563,\n",
       " 'gelecek': 564,\n",
       " 'evde': 565,\n",
       " 'eksik': 566,\n",
       " 'filmdir': 567,\n",
       " 'tane': 568,\n",
       " 'giden': 569,\n",
       " 'benzer': 570,\n",
       " 'birde': 571,\n",
       " 'hikayenin': 572,\n",
       " 'adı': 573,\n",
       " 'yıllar': 574,\n",
       " 'yol': 575,\n",
       " 'james': 576,\n",
       " 'sene': 577,\n",
       " 'izlemeyin': 578,\n",
       " 'fi̇lmi̇n': 579,\n",
       " 'izlemeden': 580,\n",
       " 'arasındaki': 581,\n",
       " 'yapıt': 582,\n",
       " 'heyecan': 583,\n",
       " 'sen': 584,\n",
       " 'önüne': 585,\n",
       " 'aldım': 586,\n",
       " 'seyirciyi': 587,\n",
       " 'olmus': 588,\n",
       " 'rahatsız': 589,\n",
       " 'diyaloglar': 590,\n",
       " 'derecede': 591,\n",
       " 'üstüne': 592,\n",
       " 'efsane': 593,\n",
       " 'belgesel': 594,\n",
       " 'türkiye': 595,\n",
       " 'gelmiş': 596,\n",
       " 'çıkarmış': 597,\n",
       " 'gelir': 598,\n",
       " 'sevenler': 599,\n",
       " 'michael': 600,\n",
       " 'dünyanın': 601,\n",
       " 'dedim': 602,\n",
       " 'onlar': 603,\n",
       " 'anlamadım': 604,\n",
       " 'ortada': 605,\n",
       " 'olmadığı': 606,\n",
       " 'psikolojik': 607,\n",
       " 'başarılıydı': 608,\n",
       " 'uygun': 609,\n",
       " 'adlı': 610,\n",
       " 'anne': 611,\n",
       " 'akıcı': 612,\n",
       " 'sıcak': 613,\n",
       " 'özgün': 614,\n",
       " 'takip': 615,\n",
       " 'üstelik': 616,\n",
       " 'edici': 617,\n",
       " 'kalıyor': 618,\n",
       " 'sade': 619,\n",
       " 'etkili': 620,\n",
       " 'başından': 621,\n",
       " 'vermek': 622,\n",
       " 'geçmiş': 623,\n",
       " 'fark': 624,\n",
       " 'dahi': 625,\n",
       " 'verdim': 626,\n",
       " 'olup': 627,\n",
       " 'hangi': 628,\n",
       " 'seyirciye': 629,\n",
       " 'not': 630,\n",
       " 'hani': 631,\n",
       " 'ondan': 632,\n",
       " 'arkadaş': 633,\n",
       " 'sefer': 634,\n",
       " 'olsada': 635,\n",
       " 'oyuncuları': 636,\n",
       " 'kırıklığına': 637,\n",
       " 'dönem': 638,\n",
       " 'çeken': 639,\n",
       " 'finali': 640,\n",
       " 'anlamıyla': 641,\n",
       " 'çocuklar': 642,\n",
       " 'kahraman': 643,\n",
       " 'hayatı': 644,\n",
       " 'izleyip': 645,\n",
       " 'oynayan': 646,\n",
       " 'vermiş': 647,\n",
       " 'gösteriyor': 648,\n",
       " 'dün': 649,\n",
       " 'konuda': 650,\n",
       " 'başarıyor': 651,\n",
       " 'boşa': 652,\n",
       " 'gece': 653,\n",
       " 'kimi': 654,\n",
       " 'hemde': 655,\n",
       " 'söylemek': 656,\n",
       " 'sıra': 657,\n",
       " 'karakterleri': 658,\n",
       " 'orjinal': 659,\n",
       " 'adamı': 660,\n",
       " 'yandan': 661,\n",
       " 'derin': 662,\n",
       " 'iyisi': 663,\n",
       " 'gelince': 664,\n",
       " 'kızın': 665,\n",
       " 'onların': 666,\n",
       " 'çıktı': 667,\n",
       " 'olursa': 668,\n",
       " 'ince': 669,\n",
       " 'gene': 670,\n",
       " 'yarım': 671,\n",
       " 'oyunculukları': 672,\n",
       " 'garip': 673,\n",
       " 'insanları': 674,\n",
       " 'neler': 675,\n",
       " 'aday': 676,\n",
       " 'kadro': 677,\n",
       " 'espriler': 678,\n",
       " 'dahil': 679,\n",
       " 'karanlık': 680,\n",
       " 'olumsuz': 681,\n",
       " 'olmadığını': 682,\n",
       " 'hayatın': 683,\n",
       " 'işin': 684,\n",
       " 'yeri': 685,\n",
       " 'çekim': 686,\n",
       " 'gördüm': 687,\n",
       " 'yılın': 688,\n",
       " 'yanlari': 689,\n",
       " 'olunca': 690,\n",
       " 'ilerliyor': 691,\n",
       " 'göze': 692,\n",
       " 'yılında': 693,\n",
       " 'kendimi': 694,\n",
       " 'bayıldım': 695,\n",
       " 'tatlı': 696,\n",
       " 'yan': 697,\n",
       " 'rolü': 698,\n",
       " 'ilerleyen': 699,\n",
       " 'dramatik': 700,\n",
       " 'kadının': 701,\n",
       " 'can': 702,\n",
       " 'olayı': 703,\n",
       " 'aşık': 704,\n",
       " 'kelime': 705,\n",
       " 'olacağını': 706,\n",
       " 'alt': 707,\n",
       " 'man': 708,\n",
       " 'yaş': 709,\n",
       " 'aksine': 710,\n",
       " 'ettim': 711,\n",
       " 'sonraki': 712,\n",
       " 'bakımından': 713,\n",
       " 'dövüş': 714,\n",
       " 'filmiydi': 715,\n",
       " 'karşımıza': 716,\n",
       " 'olsaydı': 717,\n",
       " 'kült': 718,\n",
       " 'yaşadığı': 719,\n",
       " 'istediği': 720,\n",
       " 'istiyorsanız': 721,\n",
       " 'i̇şte': 722,\n",
       " 'başarısız': 723,\n",
       " 'sayesinde': 724,\n",
       " 'çekilen': 725,\n",
       " 'kafa': 726,\n",
       " 'yapmaya': 727,\n",
       " 'seven': 728,\n",
       " 'sergilemiş': 729,\n",
       " 'izlemiş': 730,\n",
       " 'cidden': 731,\n",
       " 'keyifle': 732,\n",
       " 'insana': 733,\n",
       " 'türü': 734,\n",
       " 'samimi': 735,\n",
       " 'etkisi': 736,\n",
       " 'bunları': 737,\n",
       " 'savaşı': 738,\n",
       " 'diyebiliriz': 739,\n",
       " 'ardından': 740,\n",
       " 'benziyor': 741,\n",
       " 'etmiş': 742,\n",
       " 'yüzünden': 743,\n",
       " 'devamı': 744,\n",
       " 'gençlik': 745,\n",
       " 'anlatmak': 746,\n",
       " 'teknik': 747,\n",
       " 'david': 748,\n",
       " 'bunların': 749,\n",
       " 'fransız': 750,\n",
       " 'hava': 751,\n",
       " 'anlamsız': 752,\n",
       " 'elbette': 753,\n",
       " 'sizin': 754,\n",
       " 'elde': 755,\n",
       " 'kısaca': 756,\n",
       " 'zamandır': 757,\n",
       " 'değilim': 758,\n",
       " 'yabancı': 759,\n",
       " 'sürü': 760,\n",
       " 'yarısı': 761,\n",
       " 'tadında': 762,\n",
       " 'ister': 763,\n",
       " 'dört': 764,\n",
       " 'imza': 765,\n",
       " 'performansları': 766,\n",
       " 'oldugunu': 767,\n",
       " 'kişinin': 768,\n",
       " 'kitabı': 769,\n",
       " 'beri': 770,\n",
       " 'hayranı': 771,\n",
       " 'görüyoruz': 772,\n",
       " 'idi': 773,\n",
       " 'araya': 774,\n",
       " 'tarihi': 775,\n",
       " 'izlenecek': 776,\n",
       " 'kat': 777,\n",
       " 'konuya': 778,\n",
       " 'izleyici': 779,\n",
       " 'saygı': 780,\n",
       " 'anlatım': 781,\n",
       " 'hayatını': 782,\n",
       " 'çarpıcı': 783,\n",
       " 'karakterin': 784,\n",
       " 'hayata': 785,\n",
       " 'yerden': 786,\n",
       " 'niro': 787,\n",
       " 'haline': 788,\n",
       " 'senaryonun': 789,\n",
       " 'tarihinin': 790,\n",
       " 'süresi': 791,\n",
       " 'gerçi': 792,\n",
       " 'rolünde': 793,\n",
       " 'planda': 794,\n",
       " 'kitap': 795,\n",
       " 'ismi': 796,\n",
       " 'fi̇lm': 797,\n",
       " 'gerekiyor': 798,\n",
       " 'tebrik': 799,\n",
       " 'başladı': 800,\n",
       " 'beklediğim': 801,\n",
       " 'ettiği': 802,\n",
       " 'kendisine': 803,\n",
       " 'yaşam': 804,\n",
       " 'abd': 805,\n",
       " 'onları': 806,\n",
       " 'yaa': 807,\n",
       " 'efektleri': 808,\n",
       " 'emek': 809,\n",
       " 'olmadan': 810,\n",
       " 'izleyiciyi': 811,\n",
       " 'anlam': 812,\n",
       " 'yerlerde': 813,\n",
       " 'serisi': 814,\n",
       " 'ortalama': 815,\n",
       " 'itibariyle': 816,\n",
       " 'değildir': 817,\n",
       " 'biriydi': 818,\n",
       " 'burda': 819,\n",
       " 'türden': 820,\n",
       " 'arka': 821,\n",
       " 'olağanüstü': 822,\n",
       " 'sahnesinde': 823,\n",
       " 'oyuncusu': 824,\n",
       " 'örnek': 825,\n",
       " 'yaşayan': 826,\n",
       " 'jim': 827,\n",
       " 'nedir': 828,\n",
       " 'iyice': 829,\n",
       " 'bond': 830,\n",
       " 'abartılı': 831,\n",
       " 'atmosfer': 832,\n",
       " 'yorumlara': 833,\n",
       " 'beğendiğim': 834,\n",
       " 'görünce': 835,\n",
       " 'türünün': 836,\n",
       " 'mevcut': 837,\n",
       " 'halde': 838,\n",
       " 'yeterli': 839,\n",
       " 'üstünde': 840,\n",
       " 'i̇yi̇': 841,\n",
       " 'sıkıldım': 842,\n",
       " 'sert': 843,\n",
       " 'isteyen': 844,\n",
       " 'kan': 845,\n",
       " 'milyon': 846,\n",
       " 'öneririm': 847,\n",
       " 'ölüm': 848,\n",
       " 'olayların': 849,\n",
       " 'yaratıcı': 850,\n",
       " 'hadi': 851,\n",
       " 'sorun': 852,\n",
       " 'benden': 853,\n",
       " 'türkçe': 854,\n",
       " 'yönetmenlik': 855,\n",
       " 'olayları': 856,\n",
       " 'aklıma': 857,\n",
       " 'kotu': 858,\n",
       " 'jack': 859,\n",
       " 'soru': 860,\n",
       " 'zamanki': 861,\n",
       " 'verilen': 862,\n",
       " 'dünyada': 863,\n",
       " 'gişe': 864,\n",
       " 'hafta': 865,\n",
       " 'rezalet': 866,\n",
       " 'yerini': 867,\n",
       " 'biçimde': 868,\n",
       " 'herhangi': 869,\n",
       " 'zorunda': 870,\n",
       " 'yılmaz': 871,\n",
       " 'yapmışlar': 872,\n",
       " 'güldüm': 873,\n",
       " 'anlamak': 874,\n",
       " 'etmiyorum': 875,\n",
       " 'bitti': 876,\n",
       " 'olmadı': 877,\n",
       " 'şahsen': 878,\n",
       " 'sağlık': 879,\n",
       " 'paraya': 880,\n",
       " 'johnny': 881,\n",
       " 'rahatlıkla': 882,\n",
       " 'alakası': 883,\n",
       " 'başlar': 884,\n",
       " 'kendinizi': 885,\n",
       " 'yaşanan': 886,\n",
       " 'olumlu': 887,\n",
       " 'sebep': 888,\n",
       " 'mesajlar': 889,\n",
       " 'ders': 890,\n",
       " 'oldugu': 891,\n",
       " 'bruce': 892,\n",
       " 'etti': 893,\n",
       " 'şaşırtıcı': 894,\n",
       " 'ödül': 895,\n",
       " 'defalarca': 896,\n",
       " 'olanlar': 897,\n",
       " 'kaldı': 898,\n",
       " 'itibaren': 899,\n",
       " 'kötüydü': 900,\n",
       " 'nedense': 901,\n",
       " 'yorumlar': 902,\n",
       " 'allah': 903,\n",
       " 'izleyen': 904,\n",
       " 'yarı': 905,\n",
       " 'yola': 906,\n",
       " 'numara': 907,\n",
       " 'seyirci': 908,\n",
       " 'veriyorum': 909,\n",
       " 'valla': 910,\n",
       " 'şeyleri': 911,\n",
       " 'zamana': 912,\n",
       " 'hariç': 913,\n",
       " 'havası': 914,\n",
       " 'ters': 915,\n",
       " 'eleştiri': 916,\n",
       " 'altın': 917,\n",
       " 'olamaz': 918,\n",
       " 'işler': 919,\n",
       " 'zeki': 920,\n",
       " 'aldı': 921,\n",
       " 'suç': 922,\n",
       " 'cem': 923,\n",
       " 'zira': 924,\n",
       " 'isterim': 925,\n",
       " 'iğrenç': 926,\n",
       " 'adamlar': 927,\n",
       " 'haliyle': 928,\n",
       " 'seyrettim': 929,\n",
       " 'yerli': 930,\n",
       " 'derken': 931,\n",
       " 'yardımcı': 932,\n",
       " 'gösterime': 933,\n",
       " 'gidiyor': 934,\n",
       " 'bitiyor': 935,\n",
       " 'unutulmaz': 936,\n",
       " 'örneği': 937,\n",
       " 'olmasını': 938,\n",
       " 'emeği': 939,\n",
       " 'oyunculuğunu': 940,\n",
       " 'olmaya': 941,\n",
       " 'nedeni': 942,\n",
       " 'polisiye': 943,\n",
       " 'siyah': 944,\n",
       " 'konunun': 945,\n",
       " 'seyirlik': 946,\n",
       " 'senaryoya': 947,\n",
       " 'bilimkurgu': 948,\n",
       " 'izleyiciye': 949,\n",
       " 'ait': 950,\n",
       " 'peki': 951,\n",
       " 'şiddet': 952,\n",
       " 'toplam': 953,\n",
       " 'birden': 954,\n",
       " 'diyor': 955,\n",
       " 'hayli': 956,\n",
       " 'puanım': 957,\n",
       " 'olmuyor': 958,\n",
       " 'konusunu': 959,\n",
       " 'duruyor': 960,\n",
       " 'bakalım': 961,\n",
       " 'katılıyorum': 962,\n",
       " 'acı': 963,\n",
       " 'kızı': 964,\n",
       " 'gördüğüm': 965,\n",
       " 'birbirine': 966,\n",
       " 'adını': 967,\n",
       " 'net': 968,\n",
       " 'hikayeyi': 969,\n",
       " 'gösteren': 970,\n",
       " 'dönemde': 971,\n",
       " 'fragmanı': 972,\n",
       " 'western': 973,\n",
       " 'çıkar': 974,\n",
       " 'süperdi': 975,\n",
       " 'kaldım': 976,\n",
       " 'önceden': 977,\n",
       " 'belkide': 978,\n",
       " 'avrupa': 979,\n",
       " 'henüz': 980,\n",
       " 'hikayesini': 981,\n",
       " 'bekliyordum': 982,\n",
       " 'oynuyor': 983,\n",
       " 'havada': 984,\n",
       " 'birini': 985,\n",
       " 'emin': 986,\n",
       " 'batman': 987,\n",
       " 'tadı': 988,\n",
       " 'mekan': 989,\n",
       " 'olma': 990,\n",
       " 'sakin': 991,\n",
       " 'verici': 992,\n",
       " 'ziyade': 993,\n",
       " 'isteyenler': 994,\n",
       " 'spoiler': 995,\n",
       " 'atmosferi': 996,\n",
       " 'çektiği': 997,\n",
       " 'izlesin': 998,\n",
       " 'başarmış': 999,\n",
       " 'dans': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer = Tokenizer(num_words=num_words)    # Create tokenizer (Take only first 14000 words)\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data)              # Create tokens from our dataset\n",
    "tokenizer.word_index                      # Display tokens and their index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oyuncular cekim cok cok amatördü hikayeyinin anlami yok yarim yamalak sacma bitis oldu begenemedim\n",
      "[120, 9947, 43, 43, 27521, 98844, 27522, 11, 6703, 9524, 1366, 67403, 90, 33541]\n"
     ]
    }
   ],
   "source": [
    "x_train_tokens = tokenizer.texts_to_sequences(x_train)    # Convert comments using tokens\n",
    "x_test_tokens = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "print(x_train[2340])\n",
    "print(x_train_tokens[2340])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate some statistic about data and decide the size of the comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  33.50765392627041\n",
      "std:  59.82182649168789\n",
      "max_token_length:  123\n",
      "cover range:  0.960313423436516\n"
     ]
    }
   ],
   "source": [
    "# Calculate length of the comments and choose common length\n",
    "num_tokens = [len(tokens) for tokens in x_train_tokens + x_test_tokens]\n",
    "num_tokens = np.array(num_tokens)\n",
    "\n",
    "max_tokens = int(np.mean(num_tokens) + 1.5 * np.std(num_tokens))\n",
    "print('mean: ', np.mean(num_tokens))\n",
    "print('std: ', np.std(num_tokens))\n",
    "print('max_token_length: ', max_tokens)\n",
    "print('cover range: ', np.sum(num_tokens < max_tokens) / len(num_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Make all comments the same size (Padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66057, 123)\n",
      "(16515, 123)\n"
     ]
    }
   ],
   "source": [
    "# Make all comments in same length with padding\n",
    "x_train_tokens = pad_sequences(x_train_tokens, maxlen=max_tokens)\n",
    "x_test_tokens = pad_sequences(x_test_tokens, maxlen=max_tokens)\n",
    "print(x_train_tokens.shape)\n",
    "print(x_test_tokens.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get pre-created embedding vectors and make an embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "f = open('embedding_vectors.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:])\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220641"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words = len(tokenizer.word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i < num_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "num_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and Compile Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\Anaconda3\\envs\\tensorenviron\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_layer (Embedding)  (None, 123, 300)          66192300  \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 123, 64)           96064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 41, 64)            0         \n",
      "_________________________________________________________________\n",
      "zero_padding1d (ZeroPadding1 (None, 43, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 43, 128)           41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 14, 128)           0         \n",
      "_________________________________________________________________\n",
      "zero_padding1d_1 (ZeroPaddin (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 12, 256)           164096    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 67,019,887\n",
      "Trainable params: 827,587\n",
      "Non-trainable params: 66,192,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "                    # input_dim: # of words, output_dim: # of embedding vector size, input_len: max token size\n",
    "model.add(Embedding(input_dim=num_words,\n",
    "                    output_dim=embedding_dim,\n",
    "                    embeddings_initializer=Constant(embedding_matrix),\n",
    "                    input_length=max_tokens,\n",
    "                    trainable=False,\n",
    "                    name='embedding_layer'))\n",
    "\n",
    "model.add(Conv1D(64, 5, strides=1, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(3, strides=3))\n",
    "model.add(ZeroPadding1D(1))\n",
    "model.add(Conv1D(128, 5, strides=1, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(3, strides=3))\n",
    "model.add(ZeroPadding1D(1))\n",
    "model.add(Conv1D(256, 5, strides=1, activation='relu'))\n",
    "model.add(MaxPooling1D(3, strides=3))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_class, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train, Test and Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 59451 samples, validate on 6606 samples\n",
      "Epoch 1/5\n",
      "59451/59451 [==============================] - 26s 442us/sample - loss: 0.8153 - acc: 0.6140 - val_loss: 0.7507 - val_acc: 0.6565\n",
      "Epoch 2/5\n",
      "59451/59451 [==============================] - 21s 360us/sample - loss: 0.7385 - acc: 0.6639 - val_loss: 0.7333 - val_acc: 0.6653\n",
      "Epoch 3/5\n",
      "59451/59451 [==============================] - 21s 359us/sample - loss: 0.7142 - acc: 0.6788 - val_loss: 0.7370 - val_acc: 0.6647\n",
      "Epoch 4/5\n",
      "59451/59451 [==============================] - 21s 357us/sample - loss: 0.6924 - acc: 0.6907 - val_loss: 0.7354 - val_acc: 0.6662\n",
      "Epoch 5/5\n",
      "59451/59451 [==============================] - 21s 358us/sample - loss: 0.6679 - acc: 0.7042 - val_loss: 0.7303 - val_acc: 0.6695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c32300b088>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_tokens, y_train, validation_split=0.1, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16515/16515 [==============================] - 3s 178us/sample - loss: 0.7327 - acc: 0.6691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7327419369176702, 0.6691493]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_tokens, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_review(review):\n",
    "    classes = ['negative', 'normal', 'positive']\n",
    "    review_tokens = tokenizer.texts_to_sequences([review])\n",
    "    review_pad = pad_sequences(review_tokens, maxlen=max_tokens)\n",
    "    pred = model.predict(review_pad)\n",
    "    print(pred)\n",
    "    class_idx = np.argmax(pred)\n",
    "    return classes[class_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.14561127 0.54823905 0.30614966]]\n",
      "normal\n",
      "[[0.07386654 0.6931705  0.23296297]]\n",
      "normal\n",
      "[[0.9301333  0.06310222 0.00676446]]\n",
      "negative\n",
      "[[0.41087717 0.2922061  0.2969167 ]]\n",
      "negative\n",
      "[[0.02168684 0.2733658  0.7049473 ]]\n",
      "positive\n",
      "[[0.39184412 0.54884225 0.05931357]]\n",
      "normal\n"
     ]
    }
   ],
   "source": [
    "print(predict_review('ilk başlar ken kötü aksiyon hissi veriyo gittikce merak uyandırıyor bence izlenmezze bişey kaybetilmez'))\n",
    "print(predict_review('tekrar filmerinin ilklerini aratığı tezini destekliyor yinede kötü değil'))\n",
    "print(predict_review('internetten yorumlara baktım gittim hayatimda izlediğim berbat filmlerden konu saçma oyunculuk kötü ben pişman oldum'))\n",
    "print(predict_review('i̇zlediğim kötü filmler arasında olsunda nolursa olsun gidicek arkadaşlara başka filme gitmelerini öneririm'))\n",
    "print(predict_review('dylan minnette olduğu izlediğim sadece evde geçmesi biraz sıkıcı olabilir konu sürüklemesi falan harika'))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Convert tokens into string, by inversing the word_index dictionary\n",
    "idx = tokenizer.word_index\n",
    "inverse_map = dict(zip(idx.values(), idx.keys()))\n",
    "\n",
    "def tokens_to_string(tokens):\n",
    "    words = [inverse_map[token] for token in tokens if token != 0]\n",
    "    text = ' '.join(words)\n",
    "    return text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorenviron",
   "language": "python",
   "name": "tensorenviron"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
